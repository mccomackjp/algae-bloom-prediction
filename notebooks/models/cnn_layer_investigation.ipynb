{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Activation, MaxPooling2D\n",
    "\n",
    "from sklearn.metrics import recall_score, confusion_matrix, precision_score\n",
    "from scripts.model_functions import create_model\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables to be used in Keras and the CNN\n",
    "\n",
    "# number of items to use for training\n",
    "BATCH_SIZE = 400 \n",
    "\n",
    "# Number of identifying classes \n",
    "#   WE have two, Bloom and no bloom 1/0\n",
    "NUM_CLASSES = 2 \n",
    "\n",
    "# number of times to repeat process\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('../../data/cleaned/site1_vineyard.csv')\n",
    "df_test = pd.read_csv('../../data/cleaned/site2_bird.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "df_train = df_train.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "df_train['BGA (ug/L)'] = target\n",
    "\n",
    "\n",
    "target = df_test['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "df_test = df_test.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "df_test['BGA (ug/L)'] = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = df_train['Date (mm.dd.yyyy)'] + ' '+ df_train['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "df_train['Timestamp'] = timestamp\n",
    "\n",
    "timestamp = df_test['Date (mm.dd.yyyy)'] + ' '+ df_test['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "df_test['Timestamp'] = timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont need data and time now that we have Timestamp. Lets remove them\n",
    "\n",
    "df_train = df_train.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n",
    "df_test = df_test.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = df_train['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "df_train['Bloom'] = train_target\n",
    "\n",
    "test_target = df_test['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "df_test['Bloom'] = test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset_columns = ['Temp C','Sp Cond (uS/cm)', 'pH (mV)','pH', 'Turbidity (NTU)', 'ODOSat%','ODO (mg/L)', 'Bloom']\n",
    "scaler = MinMaxScaler()\n",
    "ds_scaled = scaler.fit_transform(df_train[dataset_columns])\n",
    "df_train = pd.DataFrame(ds_scaled,columns=dataset_columns)\n",
    "\n",
    "ds_scaled = scaler.fit_transform(df_test[dataset_columns])\n",
    "df_test = pd.DataFrame(ds_scaled,columns=dataset_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to take a moving window of the data of 10 time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "determines the window size for the daata set\n",
    "@param dataset - The dataset to get windows for\n",
    "@param window_size - the size of the window  \n",
    "@param shift - the amout to shift the window\n",
    "'''\n",
    "def windows(dataset, window_size, shift):\n",
    "    start = 0\n",
    "    while start+window_size < dataset.shape[0]: \n",
    "        yield (int(start), int(start+window_size))\n",
    "        # shift the window five blocks of time\n",
    "        start += shift\n",
    "        if start % 300 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format(((start+window_size) / dataset.shape[0]) * 100 ))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Segments the dataset based on the parameters that are passed in.\n",
    "@param dataset - the dataset to segment into window\n",
    "@param columns - the array of columns from the dataset to be looked at\n",
    "@param window_size - the size of the window you would like to be looked at. Defualt is 10\n",
    "\n",
    "'''\n",
    "def segment_dataset(dataset, columns, target, window_size=10):    \n",
    "    print('WINDOW SIZE',window_size)\n",
    "    print('NUMBER OF COULUMNS',len(columns))\n",
    "    segments = np.empty((0, window_size, len(columns)))\n",
    "    labels = np.empty((0))\n",
    "    count = 0\n",
    "    for (start, end) in windows(dataset, window_size, 1):\n",
    "        count+=1\n",
    "        values = dataset[columns][start:end]\n",
    "        if(values.shape[0] == window_size):\n",
    "            segments = np.vstack([segments, np.stack([values])])\n",
    "            # Takes the larger of the two variables if there are more than one. \n",
    "            # This makes it more likly to predict a bloom. Can be changed to iloc[0] to\n",
    "            # be less likly to predict a bloom (more 0s in the label array)\n",
    "            \n",
    "            labels = np.append(labels, dataset[target][start:end].mode().iloc[-1])\n",
    "        else:\n",
    "            print(\"No more Windows available... Exiting\")\n",
    "            break\n",
    "    return (segments, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.63% done\n",
      "Window Segmentation 3.21% done\n",
      "Window Segmentation 4.80% done\n",
      "Window Segmentation 6.38% done\n",
      "Window Segmentation 7.96% done\n",
      "Window Segmentation 9.55% done\n",
      "Window Segmentation 11.13% done\n",
      "Window Segmentation 12.71% done\n",
      "Window Segmentation 14.30% done\n",
      "Window Segmentation 15.88% done\n",
      "Window Segmentation 17.46% done\n",
      "Window Segmentation 19.05% done\n",
      "Window Segmentation 20.63% done\n",
      "Window Segmentation 22.21% done\n",
      "Window Segmentation 23.80% done\n",
      "Window Segmentation 25.38% done\n",
      "Window Segmentation 26.96% done\n",
      "Window Segmentation 28.55% done\n",
      "Window Segmentation 30.13% done\n",
      "Window Segmentation 31.71% done\n",
      "Window Segmentation 33.30% done\n",
      "Window Segmentation 34.88% done\n",
      "Window Segmentation 36.46% done\n",
      "Window Segmentation 38.05% done\n",
      "Window Segmentation 39.63% done\n",
      "Window Segmentation 41.21% done\n",
      "Window Segmentation 42.80% done\n",
      "Window Segmentation 44.38% done\n",
      "Window Segmentation 45.97% done\n",
      "Window Segmentation 47.55% done\n",
      "Window Segmentation 49.13% done\n",
      "Window Segmentation 50.72% done\n",
      "Window Segmentation 52.30% done\n",
      "Window Segmentation 53.88% done\n",
      "Window Segmentation 55.47% done\n",
      "Window Segmentation 57.05% done\n",
      "Window Segmentation 58.63% done\n",
      "Window Segmentation 60.22% done\n",
      "Window Segmentation 61.80% done\n",
      "Window Segmentation 63.38% done\n",
      "Window Segmentation 64.97% done\n",
      "Window Segmentation 66.55% done\n",
      "Window Segmentation 68.13% done\n",
      "Window Segmentation 69.72% done\n",
      "Window Segmentation 71.30% done\n",
      "Window Segmentation 72.88% done\n",
      "Window Segmentation 74.47% done\n",
      "Window Segmentation 76.05% done\n",
      "Window Segmentation 77.63% done\n",
      "Window Segmentation 79.22% done\n",
      "Window Segmentation 80.80% done\n",
      "Window Segmentation 82.38% done\n",
      "Window Segmentation 83.97% done\n",
      "Window Segmentation 85.55% done\n",
      "Window Segmentation 87.13% done\n",
      "Window Segmentation 88.72% done\n",
      "Window Segmentation 90.30% done\n",
      "Window Segmentation 91.88% done\n",
      "Window Segmentation 93.47% done\n",
      "Window Segmentation 95.05% done\n",
      "Window Segmentation 96.63% done\n",
      "Window Segmentation 98.22% done\n",
      "Window Segmentation 99.80% done\n",
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.81% done\n",
      "Window Segmentation 3.56% done\n",
      "Window Segmentation 5.32% done\n",
      "Window Segmentation 7.07% done\n",
      "Window Segmentation 8.83% done\n",
      "Window Segmentation 10.58% done\n",
      "Window Segmentation 12.34% done\n",
      "Window Segmentation 14.09% done\n",
      "Window Segmentation 15.85% done\n",
      "Window Segmentation 17.60% done\n",
      "Window Segmentation 19.36% done\n",
      "Window Segmentation 21.11% done\n",
      "Window Segmentation 22.87% done\n",
      "Window Segmentation 24.62% done\n",
      "Window Segmentation 26.38% done\n",
      "Window Segmentation 28.13% done\n",
      "Window Segmentation 29.89% done\n",
      "Window Segmentation 31.64% done\n",
      "Window Segmentation 33.40% done\n",
      "Window Segmentation 35.15% done\n",
      "Window Segmentation 36.91% done\n",
      "Window Segmentation 38.66% done\n",
      "Window Segmentation 40.42% done\n",
      "Window Segmentation 42.17% done\n",
      "Window Segmentation 43.93% done\n",
      "Window Segmentation 45.68% done\n",
      "Window Segmentation 47.43% done\n",
      "Window Segmentation 49.19% done\n",
      "Window Segmentation 50.94% done\n",
      "Window Segmentation 52.70% done\n",
      "Window Segmentation 54.45% done\n",
      "Window Segmentation 56.21% done\n",
      "Window Segmentation 57.96% done\n",
      "Window Segmentation 59.72% done\n",
      "Window Segmentation 61.47% done\n",
      "Window Segmentation 63.23% done\n",
      "Window Segmentation 64.98% done\n",
      "Window Segmentation 66.74% done\n",
      "Window Segmentation 68.49% done\n",
      "Window Segmentation 70.25% done\n",
      "Window Segmentation 72.00% done\n",
      "Window Segmentation 73.76% done\n",
      "Window Segmentation 75.51% done\n",
      "Window Segmentation 77.27% done\n",
      "Window Segmentation 79.02% done\n",
      "Window Segmentation 80.78% done\n",
      "Window Segmentation 82.53% done\n",
      "Window Segmentation 84.29% done\n",
      "Window Segmentation 86.04% done\n",
      "Window Segmentation 87.80% done\n",
      "Window Segmentation 89.55% done\n",
      "Window Segmentation 91.31% done\n",
      "Window Segmentation 93.06% done\n",
      "Window Segmentation 94.82% done\n",
      "Window Segmentation 96.57% done\n",
      "Window Segmentation 98.33% done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "feature_columns = dataset_columns[:-1]\n",
    "(x_train, y_train) = segment_dataset(df_train, feature_columns, 'Bloom', 9)\n",
    "(x_test, y_test) = segment_dataset(df_test, feature_columns, 'Bloom', 9)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18938, 9, 7)\n",
      "(17086, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18938,)\n",
      "(17086,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping the data to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),9,7,1)\n",
    "x_test = x_test.reshape(len(x_test),9,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking apart training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (18938, 9, 7, 1)\n",
      "x_test shape: (17086, 9, 7, 1)\n",
      "y_train shape: (18938, 1)\n",
      "y_test shape: (17086, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod = ks.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_mod = ks.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "input_shape = (9,7,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the precision of the different metrics\n",
    "def create_class_predictions(pred):\n",
    "    retval = np.array([])\n",
    "    for row in pred:\n",
    "        max_value = (-1,-1)\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value[1]:\n",
    "                max_value = (index, value)\n",
    "        retval = np.append(retval, max_value[0])\n",
    "    return retval\n",
    "\n",
    "\n",
    "def create_layers(num_layers):\n",
    "    layers = [Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax', input_dim=2)]\n",
    "    for i in range(0, num_layers):\n",
    "        layers.insert(0, Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Come on, let's create the model already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And Here we go....\n",
      "Started at 2019-02-09 11:19:23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9d4de8573c04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m44\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# What is our score?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "values = []\n",
    "\n",
    "print(\"...And Here we go....\")\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Started at\",st)\n",
    "max_layers = 10\n",
    "for i in range(2, max_layers+1):\n",
    "    layers = create_layers(i)\n",
    "    model = create_model(44, 7, input_shape, NUM_CLASSES, 0.0001, layers=layers)\n",
    "    model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)\n",
    "    # What is our score?\n",
    "    score = model.evaluate(x_train, y_train_mod, verbose=0)\n",
    "    predictions = model.predict(x_test)\n",
    "    predict = create_class_predictions(predictions)\n",
    "    recall = recall_score(y_test.reshape(-1,), predict)\n",
    "    precision = precision_score(y_test.reshape(-1,), predict)\n",
    "    cm = confusion_matrix(y_test.reshape(-1,), predict)\n",
    "    value = (i, recall, precision, cm)\n",
    "    values.append(value)\n",
    "    print(\"Layers:{}, Recall:{}, Precision {}\\nCN {}\".format(i, recall, precision, cm))\n",
    "    print(\"Current Time: \", st)\n",
    "\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Finished at\",st)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And Here we go....\n",
      "Started at 2019-02-05 19:37:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Neurons: 12\n",
      "Window Size: 2\n",
      "Recall:0.0\n",
      "Precision:0.0\n",
      "CM:[[1888    0]\n",
      " [   6    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Neurons: 12\n",
      "Window Size: 3\n",
      "Recall:0.0\n",
      "Precision:0.0\n",
      "CM:[[1888    0]\n",
      " [   6    0]]\n",
      "Number of Neurons: 12\n",
      "Window Size: 4\n",
      "Recall:1.0\n",
      "Precision:0.0031678986272439284\n",
      "CM:[[   0 1888]\n",
      " [   0    6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Neurons: 12\n",
      "Window Size: 5\n",
      "Recall:0.0\n",
      "Precision:0.0\n",
      "CM:[[1888    0]\n",
      " [   6    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Neurons: 12\n",
      "Window Size: 6\n",
      "Recall:0.0\n",
      "Precision:0.0\n",
      "CM:[[1888    0]\n",
      " [   6    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Neurons: 12\n",
      "Window Size: 7\n",
      "Recall:0.0\n",
      "Precision:0.0\n",
      "CM:[[1888    0]\n",
      " [   6    0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b1d9a8498fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                   Dense(num_neurons), Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax')]\n\u001b[0;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_neurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# What is our score?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets try iterating over neurons and and window size\n",
    "values = []\n",
    "\n",
    "\n",
    "print(\"...And Here we go....\")\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Started at\",st)\n",
    "min_neurons = 12\n",
    "max_neurons = 44\n",
    "for num_neurons in range(min_neurons, max_neurons+1):\n",
    "    for window_size in range(2, 10):\n",
    "        window = (window_size, window_size)\n",
    "        layers = [Conv2D(num_neurons, window, input_shape=input_shape, activation='relu', padding='same'),\n",
    "                  Conv2D(num_neurons * 2, window_size, activation='relu', padding='same'),\n",
    "                  Dense(num_neurons), Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax')]\n",
    "        model = create_model(num_neurons, window, input_shape, NUM_CLASSES, 0.1, layers=layers)\n",
    "        model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)\n",
    "        # What is our score?\n",
    "        score = model.evaluate(x_train, y_train_mod, verbose=0)\n",
    "        predictions = model.predict(x_test)\n",
    "        predict = create_class_predictions(predictions)\n",
    "        recall = recall_score(y_test.reshape(-1,), predict)\n",
    "        precision = precision_score(y_test.reshape(-1,), predict)\n",
    "        cm = confusion_matrix(y_test.reshape(-1,), predict)\n",
    "        value = (num_neurons, window_size, recall, cm)\n",
    "        values.append(value)\n",
    "        print('Number of Neurons: {}\\nWindow Size: {}\\nRecall:{}\\nPrecision:{}\\nCM:{}'.format(num_neurons, window_size, recall, precision, cm))\n",
    "    print(values[-10])\n",
    "\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Finished at\",st)\n",
    "print(values)\n",
    "for value in values:\n",
    "    if value[2] > 0:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And Here we go....\n",
      "Started at 2019-02-05 19:41:16\n",
      "17044/17044 [==============================] - 1s 88us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer <keras.layers.pooling.MaxPooling2D object at 0x000001D1B490EB00> done and produced a recall score of 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-f90de56e7092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 metrics=['accuracy'])\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m# What is our score?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets try iterating over multiple layers and types of layers\n",
    "\n",
    "\n",
    "layers = []\n",
    "layer_to_keep = (None,0,0,None)\n",
    "choices = [\n",
    "            MaxPooling2D(pool_size=(3,3)), \n",
    "            Conv2D(44, 4, activation='relu', padding='same'),\n",
    "            Conv2D(26, 7, activation='relu', padding='same'),\n",
    "            Conv2D(44, 7, activation='relu', padding='same'),\n",
    "            Conv2D(26, 4, activation='relu', padding='same'),\n",
    "           ]\n",
    "\n",
    "def create_model_with_layer(model, layers=[]):\n",
    "    if layers:\n",
    "        for layer in layers:\n",
    "            model.add(layer)\n",
    "    return model\n",
    "\n",
    "print(\"...And Here we go....\")\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Started at\",st)\n",
    "\n",
    "for i in range(8):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    model = create_model_with_layer(model, layers)\n",
    "    for layer in choices:\n",
    "        model.add(layer)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.2)) \n",
    "        model.add(Dense(44))\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "        model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "                optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "        model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)\n",
    "        # What is our score?\n",
    "        score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "        predictions = model.predict(x_test)\n",
    "        predict = create_class_predictions(predictions)\n",
    "        recall = recall_score(y_test.reshape(-1,), predict)\n",
    "        precision = precision_score(y_test.reshape(-1,), predict)\n",
    "        cm = confusion_matrix(y_test.reshape(-1,), predict)\n",
    "\n",
    "        if recall > layer_to_keep[1] and precision > layer_to_keep[2]:\n",
    "            layer_to_keep = (layer, recall, precision,cm)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "        model = create_model_with_layer(model, layers)\n",
    "        \n",
    "        print(\"Layer {} done and produced a recall score of {}\".format(layer, recall))\n",
    "    layers.append(layer_to_keep[0])\n",
    "    layer_to_keep = (None,0,0,None)\n",
    "    print(\"Iteration {} done!\".format(i))\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Finished at\",st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for values in layers:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17044/17044 [==============================] - 2s 130us/step - loss: 0.1646 - acc: 0.9951\n",
      "Epoch 2/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0287 - acc: 0.9960\n",
      "Epoch 3/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0258 - acc: 0.9960\n",
      "Epoch 4/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0207 - acc: 0.9960\n",
      "Epoch 5/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0182 - acc: 0.9959\n",
      "Epoch 6/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0167 - acc: 0.9960\n",
      "Epoch 7/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0160 - acc: 0.9960\n",
      "Epoch 8/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0153 - acc: 0.9960\n",
      "Epoch 9/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0141 - acc: 0.9960\n",
      "Epoch 10/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 11/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0139 - acc: 0.9962\n",
      "Epoch 12/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 13/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0130 - acc: 0.9962\n",
      "Epoch 14/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0132 - acc: 0.9962\n",
      "Epoch 15/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0126 - acc: 0.9960\n",
      "Epoch 16/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0118 - acc: 0.9962\n",
      "Epoch 17/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 18/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 19/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 20/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0116 - acc: 0.9963\n",
      "Epoch 21/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0101 - acc: 0.9967\n",
      "Epoch 22/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0104 - acc: 0.9966\n",
      "Epoch 23/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0109 - acc: 0.9965\n",
      "Epoch 24/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0097 - acc: 0.9972\n",
      "Epoch 25/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0094 - acc: 0.9970\n",
      "Epoch 26/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 27/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 28/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 29/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0092 - acc: 0.9971\n",
      "Epoch 30/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0083 - acc: 0.9972\n",
      "Epoch 31/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0078 - acc: 0.9975\n",
      "Epoch 32/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 33/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0071 - acc: 0.9979: 0s - loss: 0.0073 - \n",
      "Epoch 34/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0072 - acc: 0.9974\n",
      "Epoch 35/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0085 - acc: 0.9968\n",
      "Epoch 36/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0066 - acc: 0.9978\n",
      "Epoch 37/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 38/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 39/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0070 - acc: 0.9974\n",
      "Epoch 40/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0069 - acc: 0.9972\n",
      "Epoch 41/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0061 - acc: 0.9977\n",
      "Epoch 42/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0054 - acc: 0.9981\n",
      "Epoch 43/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0057 - acc: 0.9979\n",
      "Epoch 44/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 45/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0052 - acc: 0.9982: 0s - loss: 0.0053 - acc: \n",
      "Epoch 46/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0067 - acc: 0.9977\n",
      "Epoch 47/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 48/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0055 - acc: 0.9980\n",
      "Epoch 49/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0042 - acc: 0.9985\n",
      "Epoch 50/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0040 - acc: 0.9987\n",
      "Epoch 51/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 52/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0047 - acc: 0.9984\n",
      "Epoch 53/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0050 - acc: 0.9982\n",
      "Epoch 54/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0047 - acc: 0.9984\n",
      "Epoch 55/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 56/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0045 - acc: 0.9980\n",
      "Epoch 57/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0060 - acc: 0.9977\n",
      "Epoch 58/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 59/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 60/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0038 - acc: 0.9984\n",
      "Epoch 61/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 62/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0038 - acc: 0.9983\n",
      "Epoch 63/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0053 - acc: 0.9978\n",
      "Epoch 64/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0043 - acc: 0.9981\n",
      "Epoch 65/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 66/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 67/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0042 - acc: 0.9984: 0s - loss: 0.0038 - acc: 0\n",
      "Epoch 68/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9982\n",
      "Epoch 69/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0040 - acc: 0.9986\n",
      "Epoch 70/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 71/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0034 - acc: 0.9986\n",
      "Epoch 72/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 73/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9982\n",
      "Epoch 74/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0031 - acc: 0.9987\n",
      "Epoch 75/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 76/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 77/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 78/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0033 - acc: 0.9989\n",
      "Epoch 79/100\n",
      "17044/17044 [==============================] - 1s 46us/step - loss: 0.0026 - acc: 0.9989\n",
      "Epoch 80/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0031 - acc: 0.9987\n",
      "Epoch 81/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0023 - acc: 0.9988\n",
      "Epoch 82/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 83/100\n",
      "17044/17044 [==============================] - 1s 42us/step - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 84/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0022 - acc: 0.9992\n",
      "Epoch 85/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0027 - acc: 0.9989\n",
      "Epoch 86/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 87/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0039 - acc: 0.9985\n",
      "Epoch 88/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0029 - acc: 0.9986\n",
      "Epoch 89/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 90/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0028 - acc: 0.9989\n",
      "Epoch 91/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0028 - acc: 0.9989\n",
      "Epoch 92/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0028 - acc: 0.9988\n",
      "Epoch 93/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0040 - acc: 0.9984\n",
      "Epoch 94/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0035 - acc: 0.9987\n",
      "Epoch 95/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 96/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 97/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0026 - acc: 0.9988\n",
      "Epoch 98/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 99/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 100/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0021 - acc: 0.9993\n",
      "17044/17044 [==============================] - 2s 113us/step\n",
      "RECALL: 0.8333333333333334\n",
      "PRECISION: 0.5555555555555556\n",
      "CONFUSTION MATRIX [[1884    4]\n",
      " [   1    5]]\n"
     ]
    }
   ],
   "source": [
    "# From the above cell it was found to be the following layers to be the best\n",
    "# Conv2D 44,4\n",
    "# Conv2D 44, 7\n",
    "# Conv2D 44, 4\n",
    "# Conv2D 44 7\n",
    "# Flatten()\n",
    "# Dropout(0.2)\n",
    "# Dense(44)\n",
    "# Dense(2)\n",
    "\n",
    "# let's train a model to see if we get similar results with that\n",
    "model = Sequential()\n",
    "model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 7, activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(44))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "recall = recall_score(y_test.reshape(-1,), predict)\n",
    "precision = precision_score(y_test.reshape(-1,),predict)\n",
    "cm = confusion_matrix(y_test.reshape(-1,),predict)\n",
    "print(\"RECALL:\",recall)\n",
    "print(\"PRECISION:\", precision)\n",
    "print(\"CONFUSTION MATRIX\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, cnn_model, 1)\n",
    "# ignoring dropout for deployment\n",
    "K.set_learning_phase(0)\n",
    " \n",
    "# Set a file path to save the model in.\n",
    "model_name = \"cnn_model\"\n",
    "model_version = \"1\"\n",
    "tf_path = \"./../../saved_models/{}/{}\".format(model_name, model_version)\n",
    " \n",
    "# Get the session from the Keras back-end to save the model in TF format.\n",
    "with K.get_session() as sess:\n",
    "    tf.saved_model.simple_save(sess, tf_path, inputs={'input': model.input}, outputs={t.name: t for t in model.outputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
